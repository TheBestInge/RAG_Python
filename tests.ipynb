{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    base_url=\"https://api.deepinfra.com/v1/openai\",\n",
    "    api_key=os.environ[\"DEEPINFRA_TOKEN\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncPage[Model](data=[Model(id='cognitivecomputations/dolphin-2.9.1-llama-3-70b', created=0, object='model', owned_by='deepinfra', root='cognitivecomputations/dolphin-2.9.1-llama-3-70b', parent=None), Model(id='Sao10K/L3.3-70B-Euryale-v2.3', created=0, object='model', owned_by='deepinfra', root='Sao10K/L3.3-70B-Euryale-v2.3', parent=None), Model(id='microsoft/Phi-3-medium-4k-instruct', created=0, object='model', owned_by='deepinfra', root='microsoft/Phi-3-medium-4k-instruct', parent=None), Model(id='meta-llama/Meta-Llama-3.1-8B-Instruct', created=0, object='model', owned_by='deepinfra', root='meta-llama/Meta-Llama-3.1-8B-Instruct', parent=None), Model(id='google/gemini-2.0-flash-001', created=0, object='model', owned_by='deepinfra', root='google/gemini-2.0-flash-001', parent=None), Model(id='mistralai/Mixtral-8x7B-Instruct-v0.1', created=0, object='model', owned_by='deepinfra', root='mistralai/Mixtral-8x7B-Instruct-v0.1', parent=None), Model(id='Sao10K/L3.1-70B-Euryale-v2.2', created=0, object='model', owned_by='deepinfra', root='Sao10K/L3.1-70B-Euryale-v2.2', parent=None), Model(id='meta-llama/Llama-3.3-70B-Instruct', created=0, object='model', owned_by='deepinfra', root='meta-llama/Llama-3.3-70B-Instruct', parent=None), Model(id='Qwen/QwQ-32B', created=0, object='model', owned_by='deepinfra', root='Qwen/QwQ-32B', parent=None), Model(id='deepseek-ai/DeepSeek-R1-Distill-Qwen-32B', created=0, object='model', owned_by='deepinfra', root='deepseek-ai/DeepSeek-R1-Distill-Qwen-32B', parent=None), Model(id='NovaSky-AI/Sky-T1-32B-Preview', created=0, object='model', owned_by='deepinfra', root='NovaSky-AI/Sky-T1-32B-Preview', parent=None), Model(id='google/gemma-2-27b-it', created=0, object='model', owned_by='deepinfra', root='google/gemma-2-27b-it', parent=None), Model(id='meta-llama/Meta-Llama-3.1-405B-Instruct', created=0, object='model', owned_by='deepinfra', root='meta-llama/Meta-Llama-3.1-405B-Instruct', parent=None), Model(id='mistralai/Mistral-7B-Instruct-v0.2', created=0, object='model', owned_by='deepinfra', root='mistralai/Mistral-7B-Instruct-v0.2', parent=None), Model(id='meta-llama/Meta-Llama-3-8B-Instruct', created=0, object='model', owned_by='deepinfra', root='meta-llama/Meta-Llama-3-8B-Instruct', parent=None), Model(id='Qwen/Qwen2-72B-Instruct', created=0, object='model', owned_by='deepinfra', root='Qwen/Qwen2-72B-Instruct', parent=None), Model(id='meta-llama/Meta-Llama-3-70B-Instruct', created=0, object='model', owned_by='deepinfra', root='meta-llama/Meta-Llama-3-70B-Instruct', parent=None), Model(id='Qwen/Qwen2.5-Coder-7B', created=0, object='model', owned_by='deepinfra', root='Qwen/Qwen2.5-Coder-7B', parent=None), Model(id='microsoft/Phi-4-multimodal-instruct', created=0, object='model', owned_by='deepinfra', root='microsoft/Phi-4-multimodal-instruct', parent=None), Model(id='meta-llama/Llama-3.2-3B-Instruct', created=0, object='model', owned_by='deepinfra', root='meta-llama/Llama-3.2-3B-Instruct', parent=None), Model(id='openbmb/MiniCPM-Llama3-V-2_5', created=0, object='model', owned_by='deepinfra', root='openbmb/MiniCPM-Llama3-V-2_5', parent=None), Model(id='mistralai/Mistral-Nemo-Instruct-2407', created=0, object='model', owned_by='deepinfra', root='mistralai/Mistral-Nemo-Instruct-2407', parent=None), Model(id='nvidia/Llama-3.1-Nemotron-70B-Instruct', created=0, object='model', owned_by='deepinfra', root='nvidia/Llama-3.1-Nemotron-70B-Instruct', parent=None), Model(id='Austism/chronos-hermes-13b-v2', created=0, object='model', owned_by='deepinfra', root='Austism/chronos-hermes-13b-v2', parent=None), Model(id='KoboldAI/LLaMA2-13B-Tiefighter', created=0, object='model', owned_by='deepinfra', root='KoboldAI/LLaMA2-13B-Tiefighter', parent=None), Model(id='meta-llama/Llama-2-70b-chat-hf', created=0, object='model', owned_by='deepinfra', root='meta-llama/Llama-2-70b-chat-hf', parent=None), Model(id='Sao10K/L3-8B-Lunaris-v1', created=0, object='model', owned_by='deepinfra', root='Sao10K/L3-8B-Lunaris-v1', parent=None), Model(id='meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo', created=0, object='model', owned_by='deepinfra', root='meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo', parent=None), Model(id='Qwen/Qwen2.5-Coder-32B-Instruct', created=0, object='model', owned_by='deepinfra', root='Qwen/Qwen2.5-Coder-32B-Instruct', parent=None), Model(id='microsoft/WizardLM-2-8x22B', created=0, object='model', owned_by='deepinfra', root='microsoft/WizardLM-2-8x22B', parent=None), Model(id='meta-llama/Llama-3.2-11B-Vision-Instruct', created=0, object='model', owned_by='deepinfra', root='meta-llama/Llama-3.2-11B-Vision-Instruct', parent=None), Model(id='lizpreciatior/lzlv_70b_fp16_hf', created=0, object='model', owned_by='deepinfra', root='lizpreciatior/lzlv_70b_fp16_hf', parent=None), Model(id='openchat/openchat_3.5', created=0, object='model', owned_by='deepinfra', root='openchat/openchat_3.5', parent=None), Model(id='NousResearch/Hermes-3-Llama-3.1-405B', created=0, object='model', owned_by='deepinfra', root='NousResearch/Hermes-3-Llama-3.1-405B', parent=None), Model(id='Qwen/QwQ-32B-Preview', created=0, object='model', owned_by='deepinfra', root='Qwen/QwQ-32B-Preview', parent=None), Model(id='google/gemma-1.1-7b-it', created=0, object='model', owned_by='deepinfra', root='google/gemma-1.1-7b-it', parent=None), Model(id='google/codegemma-7b-it', created=0, object='model', owned_by='deepinfra', root='google/codegemma-7b-it', parent=None), Model(id='mistralai/Mistral-7B-Instruct-v0.1', created=0, object='model', owned_by='deepinfra', root='mistralai/Mistral-7B-Instruct-v0.1', parent=None), Model(id='nvidia/Nemotron-4-340B-Instruct', created=0, object='model', owned_by='deepinfra', root='nvidia/Nemotron-4-340B-Instruct', parent=None), Model(id='Gryphe/MythoMax-L2-13b', created=0, object='model', owned_by='deepinfra', root='Gryphe/MythoMax-L2-13b', parent=None), Model(id='Gryphe/MythoMax-L2-13b-turbo', created=0, object='model', owned_by='deepinfra', root='Gryphe/MythoMax-L2-13b-turbo', parent=None), Model(id='google/gemma-2-9b-it', created=0, object='model', owned_by='deepinfra', root='google/gemma-2-9b-it', parent=None), Model(id='meta-llama/Meta-Llama-3.1-70B-Instruct', created=0, object='model', owned_by='deepinfra', root='meta-llama/Meta-Llama-3.1-70B-Instruct', parent=None), Model(id='deepseek-ai/DeepSeek-R1-Turbo', created=0, object='model', owned_by='deepinfra', root='deepseek-ai/DeepSeek-R1-Turbo', parent=None), Model(id='google/gemma-3-27b-it', created=0, object='model', owned_by='deepinfra', root='google/gemma-3-27b-it', parent=None), Model(id='deepseek-ai/DeepSeek-R1-Distill-Llama-70B', created=0, object='model', owned_by='deepinfra', root='deepseek-ai/DeepSeek-R1-Distill-Llama-70B', parent=None), Model(id='meta-llama/Llama-2-13b-chat-hf', created=0, object='model', owned_by='deepinfra', root='meta-llama/Llama-2-13b-chat-hf', parent=None), Model(id='deepseek-ai/DeepSeek-R1', created=0, object='model', owned_by='deepinfra', root='deepseek-ai/DeepSeek-R1', parent=None), Model(id='Qwen/QVQ-72B-Preview', created=0, object='model', owned_by='deepinfra', root='Qwen/QVQ-72B-Preview', parent=None), Model(id='deepseek-ai/DeepSeek-V3', created=0, object='model', owned_by='deepinfra', root='deepseek-ai/DeepSeek-V3', parent=None), Model(id='google/gemini-1.5-flash-8b', created=0, object='model', owned_by='deepinfra', root='google/gemini-1.5-flash-8b', parent=None), Model(id='openchat/openchat-3.6-8b', created=0, object='model', owned_by='deepinfra', root='openchat/openchat-3.6-8b', parent=None), Model(id='Phind/Phind-CodeLlama-34B-v2', created=0, object='model', owned_by='deepinfra', root='Phind/Phind-CodeLlama-34B-v2', parent=None), Model(id='mistralai/Mixtral-8x22B-Instruct-v0.1', created=0, object='model', owned_by='deepinfra', root='mistralai/Mixtral-8x22B-Instruct-v0.1', parent=None), Model(id='mattshumer/Reflection-Llama-3.1-70B', created=0, object='model', owned_by='deepinfra', root='mattshumer/Reflection-Llama-3.1-70B', parent=None), Model(id='deepseek-ai/DeepSeek-V3-0324', created=0, object='model', owned_by='deepinfra', root='deepseek-ai/DeepSeek-V3-0324', parent=None), Model(id='microsoft/WizardLM-2-7B', created=0, object='model', owned_by='deepinfra', root='microsoft/WizardLM-2-7B', parent=None), Model(id='mistralai/Mistral-Small-24B-Instruct-2501', created=0, object='model', owned_by='deepinfra', root='mistralai/Mistral-Small-24B-Instruct-2501', parent=None), Model(id='deepinfra/airoboros-70b', created=0, object='model', owned_by='deepinfra', root='deepinfra/airoboros-70b', parent=None), Model(id='Qwen/Qwen2-7B-Instruct', created=0, object='model', owned_by='deepinfra', root='Qwen/Qwen2-7B-Instruct', parent=None), Model(id='mistralai/Mistral-7B-Instruct-v0.3', created=0, object='model', owned_by='deepinfra', root='mistralai/Mistral-7B-Instruct-v0.3', parent=None), Model(id='Qwen/Qwen2.5-72B-Instruct', created=0, object='model', owned_by='deepinfra', root='Qwen/Qwen2.5-72B-Instruct', parent=None), Model(id='bigcode/starcoder2-15b-instruct-v0.1', created=0, object='model', owned_by='deepinfra', root='bigcode/starcoder2-15b-instruct-v0.1', parent=None), Model(id='meta-llama/Llama-3.2-90B-Vision-Instruct', created=0, object='model', owned_by='deepinfra', root='meta-llama/Llama-3.2-90B-Vision-Instruct', parent=None), Model(id='microsoft/phi-4', created=0, object='model', owned_by='deepinfra', root='microsoft/phi-4', parent=None), Model(id='Qwen/Qwen2.5-7B-Instruct', created=0, object='model', owned_by='deepinfra', root='Qwen/Qwen2.5-7B-Instruct', parent=None), Model(id='meta-llama/Llama-3.2-1B-Instruct', created=0, object='model', owned_by='deepinfra', root='meta-llama/Llama-3.2-1B-Instruct', parent=None), Model(id='cognitivecomputations/dolphin-2.6-mixtral-8x7b', created=0, object='model', owned_by='deepinfra', root='cognitivecomputations/dolphin-2.6-mixtral-8x7b', parent=None), Model(id='Sao10K/L3-70B-Euryale-v2.1', created=0, object='model', owned_by='deepinfra', root='Sao10K/L3-70B-Euryale-v2.1', parent=None), Model(id='google/gemini-1.5-flash', created=0, object='model', owned_by='deepinfra', root='google/gemini-1.5-flash', parent=None), Model(id='meta-llama/Llama-3.3-70B-Instruct-Turbo', created=0, object='model', owned_by='deepinfra', root='meta-llama/Llama-3.3-70B-Instruct-Turbo', parent=None), Model(id='meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo', created=0, object='model', owned_by='deepinfra', root='meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo', parent=None), Model(id='anthropic/claude-3-7-sonnet-latest', created=0, object='model', owned_by='deepinfra', root='anthropic/claude-3-7-sonnet-latest', parent=None)], object='list')\n"
     ]
    }
   ],
   "source": [
    "print(client.models.list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "            model=\"meta-llama/Llama-3.2-3B-Instruct\",\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": \"Write a poem about GPUs\"}\n",
    "            ],\n",
    "            #stream=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In silicon halls, a hero's might,\n",
      "A GPU stands, a wondrous sight.\n",
      "Its CUDA cores, a numerical throng,\n",
      "Performing calculations, all day long.\n",
      "\n",
      "With MHz of speed, it conquers space,\n",
      "And tames the beast of digital pace.\n",
      "Gigabytes of memory, a vast domain,\n",
      "To store and process, without a strain.\n",
      "\n",
      "Its Memory Bandwidth, a wondrous feat,\n",
      "A symphony of data, at its feet.\n",
      "Through PCIe lanes, it makes its stride,\n",
      "Transferring bits, with precision and pride.\n",
      "\n",
      "In rendering images, it shines so bright,\n",
      "A graphics powerhouse, in the digital light.\n",
      "In games and simulations, it plays its part,\n",
      "A crucial ally, for the programmer's art.\n",
      "\n",
      "With ray tracing and AI, it now can play,\n",
      "In a world of innovation, every single day.\n",
      "A leader in the field, it holds its ground,\n",
      "A testament to human ingenuity, profound.\n",
      "\n",
      "Its architecture, a marvel to behold,\n",
      "A feat of engineering, to unfold.\n",
      "From GeForce to Quadro, it bears its name,\n",
      "A GPU's prowess, in the digital frame.\n",
      "\n",
      "So here's to the GPU, a hero of our time,\n",
      "A champion of performance, sublime.\n",
      "May its calculations, forever be fast,\n",
      "And its power, forever forever last.\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
